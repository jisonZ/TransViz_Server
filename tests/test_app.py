import json
from app.entities.models import modelflow


def test_modelflow(client, app):
  #TODO: add more testing!!!
  # response = client.get('/api/v1/modelflow')
  testdata1 = {
      "name": "test1",
      "deployed": False,
      "isPublic": False,
      "flowData": '{"nodes":[{"width":300,"height":277,"id":"aiPlugin…ges":[],"viewport":{"x":-1008,"y":-727,"zoom":2}}',
  }

  testdata2 = {
      "name": "test2",
      "deployed": False,
      "isPublic": False,
      "flowData": '{"nodes":[{"width":300,"height":277,"id":"aiPlugin…ges":[],"viewport":{"x":-1008,"y":-727,"zoom":2}}',
  }
  response = client.post("http://localhost:3000/api/v1/chatflows", json=testdata1)
  response = client.post("http://localhost:3000/api/v1/chatflows", json=testdata2)
  # print(response.data)

  # with app.app_context():
  #     print(modelflow.query.all())

  response = client.get('http://localhost:3000/api/v1/chatflows')
  # print(response.data)
  response = client.get('http://localhost:3000/api/v1/chatflows/1')
  # print(response.data)
  response = client.get('http://localhost:3000/api/v1/chatflows/2')
  # print(response.data)

  testput = {
    "flowData": "{\"nodes\":[{\"width\":300,\"height\":458,\"id\":\"getApiChain_0\",\"position\":{\"x\":660,\"y\":339},\"type\":\"customNode\",\"data\":{\"label\":\"GET API Chain\",\"name\":\"getApiChain\",\"version\":1,\"type\":\"GETApiChain\",\"icon\":\"/home/haochenz/TransViz/node_modules/flowise-components/dist/nodes/chains/ApiChain/get.svg\",\"category\":\"Chains\",\"description\":\"Chain to run queries against GET API\",\"baseClasses\":[\"GETApiChain\",\"BaseChain\",\"Runnable\"],\"inputs\":{\"model\":\"\",\"apiDocs\":\"\",\"headers\":\"\",\"urlPrompt\":\"You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:\",\"ansPrompt\":\"Given this {api_response} response for {api_url}. use the given response to answer this {question}\"},\"filePath\":\"/home/haochenz/TransViz/node_modules/flowise-components/dist/nodes/chains/ApiChain/GETApiChain.js\",\"inputAnchors\":[{\"label\":\"Language Model\",\"name\":\"model\",\"type\":\"BaseLanguageModel\",\"id\":\"getApiChain_0-input-model-BaseLanguageModel\"}],\"inputParams\":[{\"label\":\"API Documentation\",\"name\":\"apiDocs\",\"type\":\"string\",\"description\":\"Description of how API works. Please refer to more <a target=\\\"_blank\\\" href=\\\"https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/api/open_meteo_docs.py\\\">examples</a>\",\"rows\":4,\"id\":\"getApiChain_0-input-apiDocs-string\"},{\"label\":\"Headers\",\"name\":\"headers\",\"type\":\"json\",\"additionalParams\":true,\"optional\":true,\"id\":\"getApiChain_0-input-headers-json\"},{\"label\":\"URL Prompt\",\"name\":\"urlPrompt\",\"type\":\"string\",\"description\":\"Prompt used to tell LLMs how to construct the URL. Must contains {api_docs} and {question}\",\"default\":\"You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:\",\"rows\":4,\"additionalParams\":true,\"id\":\"getApiChain_0-input-urlPrompt-string\"},{\"label\":\"Answer Prompt\",\"name\":\"ansPrompt\",\"type\":\"string\",\"description\":\"Prompt used to tell LLMs how to return the API response. Must contains {api_response}, {api_url}, and {question}\",\"default\":\"Given this {api_response} response for {api_url}. use the given response to answer this {question}\",\"rows\":4,\"additionalParams\":true,\"id\":\"getApiChain_0-input-ansPrompt-string\"}],\"outputs\":{},\"outputAnchors\":[{\"id\":\"getApiChain_0-output-getApiChain-GETApiChain|BaseChain|Runnable\",\"name\":\"getApiChain\",\"label\":\"GETApiChain\",\"type\":\"GETApiChain | BaseChain | Runnable\"}],\"id\":\"getApiChain_0\",\"selected\":false},\"positionAbsolute\":{\"x\":660,\"y\":339}},{\"width\":300,\"height\":669,\"id\":\"awsChatBedrock_0\",\"position\":{\"x\":813.084402210967,\"y\":622.284158239991},\"type\":\"customNode\",\"data\":{\"label\":\"AWS ChatBedrock\",\"name\":\"awsChatBedrock\",\"version\":3,\"type\":\"AWSChatBedrock\",\"icon\":\"/home/haochenz/TransViz/node_modules/flowise-components/dist/nodes/chatmodels/AWSBedrock/aws.svg\",\"category\":\"Chat Models\",\"description\":\"Wrapper around AWS Bedrock large language models that use the Chat endpoint\",\"baseClasses\":[\"AWSChatBedrock\",\"BedrockChat\",\"SimpleChatModel\",\"BaseChatModel\",\"BaseLanguageModel\",\"Runnable\"],\"credential\":\"\",\"inputs\":{\"cache\":\"\",\"region\":\"us-east-1\",\"model\":\"anthropic.claude-v2\",\"customModel\":\"\",\"temperature\":0.7,\"max_tokens_to_sample\":200},\"filePath\":\"/home/haochenz/TransViz/node_modules/flowise-components/dist/nodes/chatmodels/AWSBedrock/AWSChatBedrock.js\",\"inputAnchors\":[{\"label\":\"Cache\",\"name\":\"cache\",\"type\":\"BaseCache\",\"optional\":true,\"id\":\"awsChatBedrock_0-input-cache-BaseCache\"}],\"inputParams\":[{\"label\":\"AWS Credential\",\"name\":\"credential\",\"type\":\"credential\",\"credentialNames\":[\"awsApi\"],\"optional\":true,\"id\":\"awsChatBedrock_0-input-credential-credential\"},{\"label\":\"Region\",\"name\":\"region\",\"type\":\"options\",\"options\":[{\"label\":\"af-south-1\",\"name\":\"af-south-1\"},{\"label\":\"ap-east-1\",\"name\":\"ap-east-1\"},{\"label\":\"ap-northeast-1\",\"name\":\"ap-northeast-1\"},{\"label\":\"ap-northeast-2\",\"name\":\"ap-northeast-2\"},{\"label\":\"ap-northeast-3\",\"name\":\"ap-northeast-3\"},{\"label\":\"ap-south-1\",\"name\":\"ap-south-1\"},{\"label\":\"ap-south-2\",\"name\":\"ap-south-2\"},{\"label\":\"ap-southeast-1\",\"name\":\"ap-southeast-1\"},{\"label\":\"ap-southeast-2\",\"name\":\"ap-southeast-2\"},{\"label\":\"ap-southeast-3\",\"name\":\"ap-southeast-3\"},{\"label\":\"ap-southeast-4\",\"name\":\"ap-southeast-4\"},{\"label\":\"ap-southeast-5\",\"name\":\"ap-southeast-5\"},{\"label\":\"ap-southeast-6\",\"name\":\"ap-southeast-6\"},{\"label\":\"ca-central-1\",\"name\":\"ca-central-1\"},{\"label\":\"ca-west-1\",\"name\":\"ca-west-1\"},{\"label\":\"cn-north-1\",\"name\":\"cn-north-1\"},{\"label\":\"cn-northwest-1\",\"name\":\"cn-northwest-1\"},{\"label\":\"eu-central-1\",\"name\":\"eu-central-1\"},{\"label\":\"eu-central-2\",\"name\":\"eu-central-2\"},{\"label\":\"eu-north-1\",\"name\":\"eu-north-1\"},{\"label\":\"eu-south-1\",\"name\":\"eu-south-1\"},{\"label\":\"eu-south-2\",\"name\":\"eu-south-2\"},{\"label\":\"eu-west-1\",\"name\":\"eu-west-1\"},{\"label\":\"eu-west-2\",\"name\":\"eu-west-2\"},{\"label\":\"eu-west-3\",\"name\":\"eu-west-3\"},{\"label\":\"il-central-1\",\"name\":\"il-central-1\"},{\"label\":\"me-central-1\",\"name\":\"me-central-1\"},{\"label\":\"me-south-1\",\"name\":\"me-south-1\"},{\"label\":\"sa-east-1\",\"name\":\"sa-east-1\"},{\"label\":\"us-east-1\",\"name\":\"us-east-1\"},{\"label\":\"us-east-2\",\"name\":\"us-east-2\"},{\"label\":\"us-gov-east-1\",\"name\":\"us-gov-east-1\"},{\"label\":\"us-gov-west-1\",\"name\":\"us-gov-west-1\"},{\"label\":\"us-west-1\",\"name\":\"us-west-1\"},{\"label\":\"us-west-2\",\"name\":\"us-west-2\"}],\"default\":\"us-east-1\",\"id\":\"awsChatBedrock_0-input-region-options\"},{\"label\":\"Model Name\",\"name\":\"model\",\"type\":\"options\",\"options\":[{\"label\":\"anthropic.claude-instant-v1\",\"name\":\"anthropic.claude-instant-v1\"},{\"label\":\"anthropic.claude-v1\",\"name\":\"anthropic.claude-v1\"},{\"label\":\"anthropic.claude-v2\",\"name\":\"anthropic.claude-v2\"},{\"label\":\"meta.llama2-13b-chat-v1\",\"name\":\"meta.llama2-13b-chat-v1\"}],\"default\":\"anthropic.claude-v2\",\"id\":\"awsChatBedrock_0-input-model-options\"},{\"label\":\"Custom Model Name\",\"name\":\"customModel\",\"description\":\"If provided, will override model selected from Model Name option\",\"type\":\"string\",\"optional\":true,\"id\":\"awsChatBedrock_0-input-customModel-string\"},{\"label\":\"Temperature\",\"name\":\"temperature\",\"type\":\"number\",\"step\":0.1,\"description\":\"Temperature parameter may not apply to certain model. Please check available model parameters\",\"optional\":true,\"additionalParams\":true,\"default\":0.7,\"id\":\"awsChatBedrock_0-input-temperature-number\"},{\"label\":\"Max Tokens to Sample\",\"name\":\"max_tokens_to_sample\",\"type\":\"number\",\"step\":10,\"description\":\"Max Tokens parameter may not apply to certain model. Please check available model parameters\",\"optional\":true,\"additionalParams\":true,\"default\":200,\"id\":\"awsChatBedrock_0-input-max_tokens_to_sample-number\"}],\"outputs\":{},\"outputAnchors\":[{\"id\":\"awsChatBedrock_0-output-awsChatBedrock-AWSChatBedrock|BedrockChat|SimpleChatModel|BaseChatModel|BaseLanguageModel|Runnable\",\"name\":\"awsChatBedrock\",\"label\":\"AWSChatBedrock\",\"type\":\"AWSChatBedrock | BedrockChat | SimpleChatModel | BaseChatModel | BaseLanguageModel | Runnable\"}],\"id\":\"awsChatBedrock_0\",\"selected\":false},\"positionAbsolute\":{\"x\":813.084402210967,\"y\":622.284158239991}}],\"edges\":[],\"viewport\":{\"x\":-360.7349669285027,\"y\":-313.084265177911,\"zoom\":1.2455471586647573}}",
    "name": "testest"
  }

  response = client.put('http://localhost:3000/api/v1/chatflows/1', json=testput)
  print(response.data)